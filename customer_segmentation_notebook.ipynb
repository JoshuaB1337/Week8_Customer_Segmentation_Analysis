{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation Analysis for Marketing Strategy\n",
    "\n",
    "This notebook implements customer segmentation using K-Means and DBSCAN clustering algorithms on the Mall Customer Segmentation dataset. The analysis identifies distinct customer segments based on spending behavior and demographic characteristics, which can be used to develop targeted marketing strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from kneed import KneeLocator\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set styling for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Create output directory for plots\n",
    "if not os.path.exists('plots'):\n",
    "    os.makedirs('plots')\n",
    "    print(\"Created 'plots' directory for saving visualizations\")\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration\n",
    "\n",
    "First, we'll load the Mall Customer Segmentation dataset and explore its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Mall Customer Segmentation dataset\n",
    "try:\n",
    "    # Attempt to load the dataset from a local file\n",
    "    df = pd.read_csv('Mall_Customers.csv')\n",
    "    print(\"Dataset loaded successfully from local file.\")\n",
    "except FileNotFoundError:\n",
    "    # If file not found, download from URL\n",
    "    print(\"Local file not found. Downloading from URL...\")\n",
    "    url = \"https://raw.githubusercontent.com/jeffrey125/Mall-Customer-Segmentation/master/Mall_Customers.csv\"\n",
    "    df = pd.read_csv(url)\n",
    "    # Save locally for future use\n",
    "    df.to_csv('Mall_Customers.csv', index=False)\n",
    "    print(\"Dataset saved locally as 'Mall_Customers.csv'\")\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Checking for missing values:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "Let's visualize the distributions and relationships in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Age\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Age'], kde=True)\n",
    "plt.title('Distribution of Customer Age')\n",
    "plt.savefig('plots/age_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Annual Income\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Annual Income (k$)'], kde=True)\n",
    "plt.title('Distribution of Annual Income')\n",
    "plt.savefig('plots/income_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Spending Score\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Spending Score (1-100)'], kde=True)\n",
    "plt.title('Distribution of Spending Score')\n",
    "plt.savefig('plots/spending_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "gender_counts = df['Gender'].value_counts()\n",
    "plt.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Gender Distribution')\n",
    "plt.savefig('plots/gender_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual Income vs Spending Score - Key relationship for segmentation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Annual Income (k$)', y='Spending Score (1-100)', data=df, hue='Gender')\n",
    "plt.title('Annual Income vs Spending Score')\n",
    "plt.savefig('plots/income_vs_spending.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Now we'll prepare our data for clustering by encoding categorical variables and scaling the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataset for preprocessing\n",
    "data = df.copy()\n",
    "\n",
    "# Encode Gender (Male: 0, Female: 1)\n",
    "data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "# Features for clustering\n",
    "features = ['Age', 'Annual Income (k$)', 'Spending Score (1-100)', 'Gender']\n",
    "X = data[features]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"Data standardized.\")\n",
    "\n",
    "# Display the standardized features\n",
    "standardized_df = pd.DataFrame(X_scaled, columns=features)\n",
    "standardized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Principal Component Analysis (PCA)\n",
    "\n",
    "We'll apply PCA for dimensionality reduction and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot the PCA results\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.7)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA of Customer Data')\n",
    "plt.savefig('plots/pca_visualization.png')\n",
    "plt.show()\n",
    "\n",
    "# Explained variance\n",
    "print(f\"Explained variance ratio by the first two components: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. K-Means Clustering\n",
    "\n",
    "We'll apply K-Means clustering to identify customer segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the optimal number of clusters using the Elbow Method\n",
    "wcss = []\n",
    "silhouette_scores = []\n",
    "range_n_clusters = range(2, 11)\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    wcss.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, cluster_labels))\n",
    "\n",
    "# Plot the Elbow Method\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range_n_clusters, wcss, marker='o')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "\n",
    "# Use KneeLocator to find the elbow point\n",
    "kl = KneeLocator(range_n_clusters, wcss, curve=\"convex\", direction=\"decreasing\")\n",
    "optimal_k = kl.elbow\n",
    "print(f\"Optimal number of clusters based on Elbow Method: {optimal_k}\")\n",
    "\n",
    "# Plot Silhouette Scores\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range_n_clusters, silhouette_scores, marker='o')\n",
    "plt.title('Silhouette Score for Optimal k')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/kmeans_optimal_k.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-Means with the optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to the original dataframe\n",
    "data['KMeans_Cluster'] = kmeans_labels\n",
    "\n",
    "# Visualize the K-Means clusters in PCA space\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, cmap='viridis', alpha=0.8)\n",
    "plt.scatter(pca.transform(scaler.transform(kmeans.cluster_centers_))[:, 0],\n",
    "            pca.transform(scaler.transform(kmeans.cluster_centers_))[:, 1],\n",
    "            s=100, c='red', marker='X')\n",
    "plt.title(f'K-Means Clustering with {optimal_k} Clusters (PCA Visualization)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.savefig('plots/kmeans_clusters_pca.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the K-Means clusters\n",
    "print(\"K-Means Cluster Analysis:\")\n",
    "cluster_analysis = data.groupby('KMeans_Cluster').mean()\n",
    "cluster_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cluster sizes\n",
    "cluster_sizes = data['KMeans_Cluster'].value_counts().sort_index()\n",
    "print(\"Cluster Sizes:\")\n",
    "for cluster, size in cluster_sizes.items():\n",
    "    print(f\"Cluster {cluster}: {size} customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cluster characteristics\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.boxplot(x='KMeans_Cluster', y=feature, data=data)\n",
    "    plt.title(f'{feature} by Cluster')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/kmeans_cluster_characteristics.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. DBSCAN Clustering\n",
    "\n",
    "Let's apply DBSCAN clustering for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN with parameters based on prior analysis\n",
    "dbscan = DBSCAN(eps=1.1, min_samples=3)\n",
    "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to the dataframe\n",
    "data['DBSCAN_Cluster'] = dbscan_labels\n",
    "\n",
    "# Get number of clusters (excluding noise points with label -1)\n",
    "n_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "print(f\"DBSCAN identified {n_clusters} clusters.\")\n",
    "\n",
    "# Calculate silhouette score if possible\n",
    "if len(set(dbscan_labels)) > 1:  # Only calculate silhouette if we have more than one cluster\n",
    "    try:\n",
    "        db_silhouette = silhouette_score(X_scaled, dbscan_labels)\n",
    "        print(f\"Silhouette score: {db_silhouette:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Cannot calculate silhouette score: {e}\")\n",
    "\n",
    "# Count points in each cluster\n",
    "unique_labels, counts = np.unique(dbscan_labels, return_counts=True)\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    if label == -1:\n",
    "        print(f\"Noise points: {count}\")\n",
    "    else:\n",
    "        print(f\"Cluster {label}: {count} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize DBSCAN clusters in PCA space\n",
    "plt.figure(figsize=(12, 10))\n",
    "# Create a colormap that handles noise points (-1) differently\n",
    "n_clusters_for_color = max(1, len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, n_clusters_for_color))\n",
    "\n",
    "for i, label in enumerate(sorted(set(dbscan_labels))):\n",
    "    if label == -1:\n",
    "        # Black for noise points\n",
    "        mask = dbscan_labels == label\n",
    "        plt.scatter(X_pca[mask, 0], X_pca[mask, 1], c='black', marker='x', alpha=0.5, label='Noise')\n",
    "    else:\n",
    "        mask = dbscan_labels == label\n",
    "        color_idx = i if -1 not in dbscan_labels else i-1\n",
    "        plt.scatter(X_pca[mask, 0], X_pca[mask, 1], c=[colors[color_idx % len(colors)]], alpha=0.8, label=f'Cluster {label}')\n",
    "\n",
    "plt.title('DBSCAN Clustering Results (PCA Visualization)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.savefig('plots/dbscan_clusters_pca.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Marketing Strategy Recommendations\n",
    "\n",
    "Based on our customer segments, we can develop targeted marketing strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the segmented data\n",
    "segmented_data = df.copy()\n",
    "segmented_data['KMeans_Cluster'] = data['KMeans_Cluster']\n",
    "segmented_data['DBSCAN_Cluster'] = data['DBSCAN_Cluster']\n",
    "segmented_data.to_csv('segmented_customers.csv', index=False)\n",
    "print(\"Segmented data saved to 'segmented_customers.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Segment Descriptions and Marketing Recommendations\n",
    "\n",
    "Based on our K-Means analysis, here are the identified customer segments and recommendations:\n",
    "\n",
    "**Standard Female Customers (Cluster 0)**:\n",
    "- *Profile*: Middle-aged female customers with moderate income and moderate-to-low spending scores\n",
    "- *Recommendations*: Basic loyalty programs, practical promotions, family-oriented marketing\n",
    "\n",
    "**Young Male Spenders (Cluster 1)**:\n",
    "- *Profile*: Young male customers with moderate income but high spending scores\n",
    "- *Recommendations*: Trending products, technology-focused marketing, social media campaigns\n",
    "\n",
    "**Young Female Budget Shoppers (Cluster 2)**:\n",
    "- *Profile*: Young female customers with lower income but moderate-high spending scores\n",
    "- *Recommendations*: Value-oriented promotions, trending but affordable product lines, influencer marketing\n",
    "\n",
    "**Older Male Conservatives (Cluster 3)**:\n",
    "- *Profile*: Older male customers with moderate income and low spending scores\n",
    "- *Recommendations*: Quality-focused messaging, durability emphasis, value-for-money propositions\n",
    "\n",
    "**Affluent High-Spenders (Cluster 4)**:\n",
    "- *Profile*: Predominantly female customers with high income and very high spending scores\n",
    "- *Recommendations*: Premium loyalty programs, exclusive shopping events, personalized shopping experiences\n",
    "\n",
    "**Affluent Savers (Cluster 5)**:\n",
    "- *Profile*: Mixed gender customers with high income but very low spending scores\n",
    "- *Recommendations*: High-quality, long-lasting product marketing, emphasis on investment value, prestige branding\n",
    "\n",
    "DBSCAN analysis provided broader gender-based segments which could be useful for general gender-specific campaigns, but K-Means offered more actionable, detailed segments for targeted marketing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this analysis, we successfully identified distinct customer segments using clustering algorithms, with K-Means providing more detailed and actionable segments compared to DBSCAN for this particular dataset.\n",
    "\n",
    "**Key Insights:**\n",
    "\n",
    "1. **Segmentation Power**: Customer segmentation reveals distinct groups with varying purchasing behaviors and demographic characteristics.\n",
    "2. **Algorithm Comparison**: K-Means outperformed DBSCAN for this dataset, producing more interpretable and marketing-relevant clusters.\n",
    "3. **Marketing Applications**: Each identified segment represents a unique opportunity for targeted marketing strategies.\n",
    "4. **Future Directions**: The analysis could be enhanced by incorporating additional behavioral data, such as purchase history and browsing behavior.\n",
    "\n",
    "The segmentation results demonstrate how data-driven approaches can inform more effective marketing strategies by tailoring approaches to specific customer groups rather than using a one-size-fits-all approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
